{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIPT Train Contest EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- age — AAGE\n",
    "- class of worker — ACLSWKR\n",
    "- industry code — ADTIND\n",
    "- occupation code — ADTOCC\n",
    "- education — AHGA\n",
    "- wage per hour — AHRSPAY\n",
    "- enrolled in edu inst last wk — AHSCOL\n",
    "- marital status — AMARITL\n",
    "- major industry code — AMJIND\n",
    "- major occupation code — AMJOCC\n",
    "- mace — ARACE\n",
    "- hispanic origin — AREORGN\n",
    "- sex — ASEX\n",
    "- member of a labor union — AUNMEM\n",
    "- reason for unemployment — AUNTYPE\n",
    "- full or part time employment stat — AWKSTAT\n",
    "- capital gains — CAPGAIN\n",
    "- capital losses — CAPLOSS\n",
    "- divdends from stocks — DIVVAL\n",
    "- tax filer status — FILESTAT\n",
    "- region of previous residence — GRINREG\n",
    "- state of previous residence — GRINST\n",
    "- detailed household and family stat — HHDFMX\n",
    "- detailed household summary in household — HHDREL\n",
    "- instance weight — MARSUPWT\n",
    "- migration code-change in msa — MIGMTR1\n",
    "- migration code-change in reg — MIGMTR3\n",
    "- migration code-move within reg — MIGMTR4\n",
    "- live in this house 1 year ago — MIGSAME\n",
    "- migration prev res in sunbelt — MIGSUN\n",
    "- num persons worked for employer — NOEMP\n",
    "- family members under — 18 PARENT\n",
    "- country of birthfather — PEFNTVTY\n",
    "- country of birthmother — PEMNTVTY\n",
    "- country of birthself — PENATVTY\n",
    "- citizenship — PRCITSHP\n",
    "- own business or self employed — SEOTR\n",
    "- taxable income amount — TAXINC\n",
    "- fill inc questionnaire for veteran's admin — VETQVA\n",
    "- veterans benefits — VETYN\n",
    "- weeks worked in year — WKSWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "numeric = ['AAGE', 'ADTIND', 'ADTOCC', 'AHRSPAY', 'CAPGAIN', 'CAPLOSS',\n",
    "          'DIVVAL', 'MARSUPWT', 'NOEMP', 'SEOTR', 'VETQVA', 'VETYN']\n",
    "categ = ['ACLSWKR', 'AHGA', 'AHSCOL', 'AMARITL', 'AMJIND', 'AMJOCC',\n",
    "       'ARACE', 'AREORGN', 'ASEX', 'AUNMEM', 'AUNTYPE', 'FILESTAT',\n",
    "       'GRINREG', 'GRINST', 'HHDFMX', 'HHDREL', 'MIGMTR1', 'MIGMTR3',\n",
    "       'MIGMTR4', 'MIGSAME', 'MIGSUN', 'PARENT', 'PEFNTVTY', 'PEMNTVTY',\n",
    "       'PENATVTY', 'PRCITSHP', 'TAXINC']\n",
    "drop = ['AWKSTAT', 'WKSWORK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAGE</th>\n",
       "      <th>ACLSWKR</th>\n",
       "      <th>ADTIND</th>\n",
       "      <th>ADTOCC</th>\n",
       "      <th>AHGA</th>\n",
       "      <th>AHRSPAY</th>\n",
       "      <th>AHSCOL</th>\n",
       "      <th>AMARITL</th>\n",
       "      <th>AMJIND</th>\n",
       "      <th>AMJOCC</th>\n",
       "      <th>...</th>\n",
       "      <th>PEFNTVTY</th>\n",
       "      <th>PEMNTVTY</th>\n",
       "      <th>PENATVTY</th>\n",
       "      <th>PRCITSHP</th>\n",
       "      <th>SEOTR</th>\n",
       "      <th>TAXINC</th>\n",
       "      <th>VETQVA</th>\n",
       "      <th>VETYN</th>\n",
       "      <th>WKSWORK</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>LocalGovernment</td>\n",
       "      <td>43</td>\n",
       "      <td>10</td>\n",
       "      <td>Mastersdegree(MAMSMEngMEdMSWMBA)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Married-civilianspousepresent</td>\n",
       "      <td>Education</td>\n",
       "      <td>Professionalspecialty</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Children</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Nevermarried</td>\n",
       "      <td>Not_in_universeorchildren</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAGE          ACLSWKR  ADTIND  ADTOCC                              AHGA  \\\n",
       "0    43  LocalGovernment      43      10  Mastersdegree(MAMSMEngMEdMSWMBA)   \n",
       "1     0  Not_in_universe       0       0                          Children   \n",
       "\n",
       "   AHRSPAY           AHSCOL                        AMARITL  \\\n",
       "0        0  Not_in_universe  Married-civilianspousepresent   \n",
       "1        0  Not_in_universe                   Nevermarried   \n",
       "\n",
       "                      AMJIND                 AMJOCC  ...         PEFNTVTY  \\\n",
       "0                  Education  Professionalspecialty  ...    United-States   \n",
       "1  Not_in_universeorchildren        Not_in_universe  ...    United-States   \n",
       "\n",
       "        PEMNTVTY       PENATVTY                      PRCITSHP SEOTR  \\\n",
       "0  United-States  United-States  Native-BornintheUnitedStates     0   \n",
       "1  United-States  United-States  Native-BornintheUnitedStates     0   \n",
       "\n",
       "            TAXINC  VETQVA  VETYN  WKSWORK status  \n",
       "0  Not_in_universe       2     52       94  train  \n",
       "1  Not_in_universe       0      0       94  train  \n",
       "\n",
       "[2 rows x 43 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "# data.icol()\n",
    "\n",
    "data.loc[data['CLASS']=='50000+', 'CLASS'] = 1\n",
    "data.loc[data['CLASS']=='-50000', 'CLASS'] = 0\n",
    "data['CLASS'] = data['CLASS'].astype(int)\n",
    "data['CLASS'] = data['CLASS'].astype(bool)\n",
    "\n",
    "data.drop(categ, axis=1)\n",
    "test_data.drop(categ, axis=1)\n",
    "\n",
    "test_index = test_data['Id']\n",
    "test_data.drop('Id', axis=1)\n",
    "\n",
    "train_data = data.drop('CLASS', axis=1)\n",
    "target = data['CLASS']\n",
    "\n",
    "train_data['status'] = 'train'\n",
    "test_data['status'] = 'test'\n",
    "\n",
    "all_data = pd.concat([train_data, test_data])\n",
    "all_data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AWKSTAT** - constant, can be dropped\n",
    "\n",
    "**WKSWORK** - constant, can be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare categ\n",
    "for col in categ:\n",
    "    if col=='status':\n",
    "        continue\n",
    "    enc = LabelEncoder()\n",
    "    all_data[col] = enc.fit_transform(all_data[col])\n",
    "    \n",
    "one_hot_enc = OneHotEncoder(categorical_features='all', sparse=False)\n",
    "categ_encoded = one_hot_enc.fit_transform(all_data[categ])\n",
    "\n",
    "# all_data[numeric] = normalize(all_data[numeric], axis=0)\n",
    "\n",
    "X_train_data = np.hstack([all_data[numeric][all_data['status']=='train'], categ_encoded[:10000,:]])\n",
    "X_test_data = np.hstack([all_data[numeric][all_data['status']=='test'], categ_encoded[10000:, :]])\n",
    "\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data, y,\n",
    "                                                    test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.877 0.123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\sklearn\\metrics\\regression.py:164: DeprecationWarning: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.\n",
      "  output_errors = np.average(np.abs(y_pred - y_true),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=42, solver='newton-cg', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_clf = LogisticRegression()\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "# best l1 , 0.8695\n",
    "params = {\n",
    "    'penalty': ['l2'],\n",
    "    'C': [0.8],\n",
    "    'solver': ['newton-cg'],#['liblinear', 'lbfgs', 'sag']\n",
    "#     'tol': [0.001],\n",
    "#     'intercept_scaling': np.linspace(0.01, 100, 10)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "clf_cv = GridSearchCV(\n",
    "    LogisticRegression(n_jobs=-1, random_state=RANDOM_STATE,\n",
    "                  max_iter=100), params,  error_score= mean_absolute_error)\n",
    "\n",
    "# log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print 'score', accuracy_score(y_test, clf_cv.predict(X_test)), mean_absolute_error(y_test, clf_cv.predict(X_test))\n",
    "\n",
    "clf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# real_pred = clf_cv.predict_proba(X_test_data)[:, 1]\n",
    "\n",
    "real_pred = clf_cv.predict(X_test_data).astype(int)\n",
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': real_pred})\n",
    "ans.to_csv('ans.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model for all data\n",
    "# clf = LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
    "#           intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
    "#           penalty='l1', random_state=42, solver='liblinear', tol=0.0001,\n",
    "#           verbose=0, warm_start=False)\n",
    "\n",
    "# Model for selected features\n",
    "clf = LogisticRegression(C=0.8, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=-1,\n",
    "          penalty='l2', random_state=42, solver='newton-cg', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train_data[:, features_to_use], target)\n",
    "real_pred = clf.predict(X_test_data[:, features_to_use]).astype(int)\n",
    "\n",
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': real_pred})\n",
    "ans.to_csv('ans_log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAGE</th>\n",
       "      <th>ACLSWKR</th>\n",
       "      <th>ADTIND</th>\n",
       "      <th>ADTOCC</th>\n",
       "      <th>AHGA</th>\n",
       "      <th>AHRSPAY</th>\n",
       "      <th>AHSCOL</th>\n",
       "      <th>AMARITL</th>\n",
       "      <th>AMJIND</th>\n",
       "      <th>AMJOCC</th>\n",
       "      <th>...</th>\n",
       "      <th>PENATVTY</th>\n",
       "      <th>PRCITSHP</th>\n",
       "      <th>SEOTR</th>\n",
       "      <th>TAXINC</th>\n",
       "      <th>VETQVA</th>\n",
       "      <th>VETYN</th>\n",
       "      <th>WKSWORK</th>\n",
       "      <th>Id</th>\n",
       "      <th>status</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>33</td>\n",
       "      <td>16</td>\n",
       "      <td>Associatesdegree-occup/vocational</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Nevermarried</td>\n",
       "      <td>Retailtrade</td>\n",
       "      <td>Sales</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>Associatesdegree-academicprogram</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Married-civilianspousepresent</td>\n",
       "      <td>Manufacturing-durablegoods</td>\n",
       "      <td>Techniciansandrelatedsupport</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somecollegebutnodegree</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Married-civilianspousepresent</td>\n",
       "      <td>Not_in_universeorchildren</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>Highschoolgraduate</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Married-civilianspousepresent</td>\n",
       "      <td>Manufacturing-nondurablegoods</td>\n",
       "      <td>Sales</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>4</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Private</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>Bachelorsdegree(BAABBS)</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>Married-civilianspousepresent</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>Sales</td>\n",
       "      <td>...</td>\n",
       "      <td>United-States</td>\n",
       "      <td>Native-BornintheUnitedStates</td>\n",
       "      <td>0</td>\n",
       "      <td>Not_in_universe</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>94</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AAGE          ACLSWKR  ADTIND  ADTOCC                               AHGA  \\\n",
       "0    28          Private      33      16  Associatesdegree-occup/vocational   \n",
       "1    41          Private      11      14   Associatesdegree-academicprogram   \n",
       "2    37  Not_in_universe       0       0             Somecollegebutnodegree   \n",
       "3    43          Private      25      18                 Highschoolgraduate   \n",
       "4    36          Private      29      17            Bachelorsdegree(BAABBS)   \n",
       "\n",
       "   AHRSPAY           AHSCOL                        AMARITL  \\\n",
       "0        0  Not_in_universe                   Nevermarried   \n",
       "1        0  Not_in_universe  Married-civilianspousepresent   \n",
       "2        0  Not_in_universe  Married-civilianspousepresent   \n",
       "3        0  Not_in_universe  Married-civilianspousepresent   \n",
       "4        0  Not_in_universe  Married-civilianspousepresent   \n",
       "\n",
       "                          AMJIND                        AMJOCC  ...   \\\n",
       "0                    Retailtrade                         Sales  ...    \n",
       "1     Manufacturing-durablegoods  Techniciansandrelatedsupport  ...    \n",
       "2      Not_in_universeorchildren               Not_in_universe  ...    \n",
       "3  Manufacturing-nondurablegoods                         Sales  ...    \n",
       "4                 Transportation                         Sales  ...    \n",
       "\n",
       "        PENATVTY                      PRCITSHP SEOTR           TAXINC VETQVA  \\\n",
       "0  United-States  Native-BornintheUnitedStates     0  Not_in_universe      2   \n",
       "1  United-States  Native-BornintheUnitedStates     0  Not_in_universe      2   \n",
       "2  United-States  Native-BornintheUnitedStates     0  Not_in_universe      2   \n",
       "3  United-States  Native-BornintheUnitedStates     0  Not_in_universe      2   \n",
       "4  United-States  Native-BornintheUnitedStates     0  Not_in_universe      2   \n",
       "\n",
       "  VETYN  WKSWORK  Id  status CLASS  \n",
       "0    52       94   1    test     0  \n",
       "1    52       94   2    test     0  \n",
       "2     0       94   3    test     0  \n",
       "3    52       94   4    test     0  \n",
       "4    52       94   5    test     0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# score: 0.18496"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = []\n",
    "\n",
    "for i, coef in enumerate(clf_cv.best_estimator_.coef_[0]):\n",
    "    coefs.append((np.abs(coef), i))\n",
    "    \n",
    "coefs = sorted(coefs, reverse=True)\n",
    "\n",
    "for coef in coefs:\n",
    "    print coef\n",
    "    \n",
    "best_features = coefs[:25]\n",
    "best_indecies = map(lambda it: it[1], best_features)\n",
    "\n",
    "X_train_data[:, best_indecies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data[:, best_indecies], y,\n",
    "                                                    test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\soft\\dev\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\sag.py:267: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.8215\n"
     ]
    }
   ],
   "source": [
    "log_reg_clf = LogisticRegression()\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "# best l1 , 0.8695\n",
    "params = {\n",
    "    'penalty': ['l2'], #['l2']]\n",
    "    'C': [0.001, 0.1, 10, 50, 100, 100],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag']\n",
    "#     'tol': [0.001],\n",
    "#     'intercept_scaling': np.linspace(0.1, 100, 10)\n",
    "}\n",
    "\n",
    "\n",
    "clf_cv = GridSearchCV(\n",
    "    LogisticRegression(n_jobs=-1, random_state=RANDOM_STATE,\n",
    "                  max_iter=100), params)\n",
    "\n",
    "# log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print 'score', accuracy_score(y_test, clf_cv.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=5,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "\n",
    "# best l1 , 0.8695\n",
    "params = {\n",
    "    'n_estimators': [1000],\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'max_depth': [5, 8, 10, 15],\n",
    "    'min_samples_split': [2, 3, 5],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "clf_cv = GridSearchCV(\n",
    "    RandomForestClassifier(n_jobs=-1, random_state=RANDOM_STATE), params)\n",
    "\n",
    "# log_reg_clf.fit(X_train, y_train)\n",
    "\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print 'score', accuracy_score(y_test, clf_cv.predict(X_test))\n",
    "\n",
    "clf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Best model for feature selected data\n",
    "clf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=15, max_features='sqrt', max_leaf_nodes=None,\n",
    "            min_samples_leaf=1, min_samples_split=5,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
    "\n",
    "clf.fit(X_train_data[:, features_to_use], target)\n",
    "real_pred = clf.predict(X_test_data[:, features_to_use])\n",
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': real_pred.astype(int)})\n",
    "ans.to_csv('ans_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "real_rf_pred = clf_cv.predict(X_test_data).astype(int)\n",
    "\n",
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': real_rf_pred})\n",
    "ans.to_csv('ans_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': (real_pred+real_rf_pred)/2.})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 0.881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators': [180, 190, 200, 210, 220],\n",
    "    'loss': ['deviance'],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [3], # 2\n",
    "    'min_samples_leaf': [1]\n",
    "#     'min_samples_split': [2, 3, 4]\n",
    "}\n",
    "\n",
    "clf_cv = GridSearchCV(\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE), params, n_jobs=-1)\n",
    "\n",
    "clf_cv.fit(X_train, y_train)\n",
    "\n",
    "print 'score', accuracy_score(y_test, clf_cv.predict(X_test))\n",
    "\n",
    "# 0.8795\n",
    "clf_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True, False, False, False,  True,\n",
       "        True,  True, False,  True, False,  True,  True, False,  True,\n",
       "        True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False,  True,\n",
       "       False, False, False, False,  True, False, False, False,  True,\n",
       "       False,  True, False, False,  True,  True, False,  True, False,\n",
       "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "       False,  True,  True,  True, False,  True, False, False, False,\n",
       "       False,  True,  True, False,  True, False, False, False, False,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "        True, False, False,  True, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False,  True, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True,  True, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False,  True,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False,  True, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# received from GradBoosting clf_cv.best_estimator_.feature_importances\n",
    "\n",
    "features_to_use = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
    "        True, False,  True, False,  True, False, False, False,  True,\n",
    "        True,  True, False,  True, False,  True,  True, False,  True,\n",
    "        True,  True,  True, False,  True, False,  True, False,  True,\n",
    "        True, False, False, False, False, False, False, False, False,\n",
    "        True, False, False,  True, False, False, False, False,  True,\n",
    "       False, False, False, False,  True, False, False, False,  True,\n",
    "       False,  True, False, False,  True,  True, False,  True, False,\n",
    "        True, False,  True, False,  True,  True,  True,  True,  True,\n",
    "       False,  True,  True,  True, False,  True, False, False, False,\n",
    "       False,  True,  True, False,  True, False, False, False, False,\n",
    "       False, False,  True,  True, False, False, False, False, False,\n",
    "       False, False, False, False, False,  True,  True, False,  True,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "        True, False, False,  True, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False, False,  True,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False,  True, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False,  True,  True, False, False,\n",
    "       False,  True, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False,  True,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False,  True, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False,  True, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False,  True, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False, False, False, False, False,\n",
    "       False, False, False, False, False,  True, False, False], dtype=bool);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_data[:, features_to_use], y,\n",
    "                                                    test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 0.12474 on board\n",
    "clf = GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
    "              presort='auto', random_state=42, subsample=1.0, verbose=0,\n",
    "              warm_start=False)\n",
    "\n",
    "# best score on bord with 500 estimators\n",
    "# maybe without features_to_use (use all data?) don't remember.\n",
    "clf.fit(X_train_data[:, features_to_use], target)\n",
    "real_pred = clf.predict(X_test_data[:, features_to_use])\n",
    "ans = pd.DataFrame({'Id': test_index, 'Prediction': real_pred.astype(int)})\n",
    "ans.to_csv('ans.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1 = pd.read_csv('./ans_grad.csv')\n",
    "a2 = pd.read_csv('./ans_log_reg.csv')\n",
    "a3 = pd.read_csv('./ans_rf.csv')\n",
    "\n",
    "# best score: 0.12448\n",
    "ans_combines = a1.copy()\n",
    "ans_combines['Prediction'] = \\\n",
    "  ((0.5 * a1['Prediction'] + 0.25 * a2['Prediction'] + 0.25 * a3['Prediction']) >= 0.5).astype(int)\n",
    "    \n",
    "ans_combines.to_csv('ans_comb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Prediction\n",
       "0   1           0\n",
       "1   2           1\n",
       "2   3           0\n",
       "3   4           1\n",
       "4   5           1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_combines.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
